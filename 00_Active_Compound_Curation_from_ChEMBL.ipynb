{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HEK-Research/Multitask-Deep-Learning-Affinity-Prediction/blob/Luis/00_Active_Compound_Curation_from_ChEMBL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Do NOT edit this notebook. \n",
        "## It is shared to show you the method I used in curate active compounds from original ChEMBL bioacitity dataset for individual target."
      ],
      "metadata": {
        "id": "V0eNWC_8ks1g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiptCwRzkdCM",
        "outputId": "93f8e1aa-557e-4a68-c3dd-844cdea61ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Z3UfSR7Xp0S7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Project_4_MTDNN/ChEMBL Datasets/'"
      ],
      "metadata": {
        "id": "iWdaL1eMlCLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter dataset with the multiple criteria:\n",
        "Filters:\n",
        "* 1\tHuman targets (Homo sapiens), single protein (target confidence score: 9) \n",
        "* 2\tOnly standard potency measurements (for example: EC50, IC50, Kd, Ki) were considered \n",
        "* 3\tAll compounds annotated as (‘inactive’, ‘not active’, ‘inconclusive’, ‘potential transcription error’, or ‘pan assay interference compounds (PAINS)’) were discarded.\n",
        "* 4\tOnly compounds with reported direct interactions (target relationship type: “B”)\n",
        "* 5\tExact activity measurements (“=”)\n",
        "* 6\tMolecular weight =< 1000 Da \n",
        "* 7\tpChEMBL value (>=6, as \"Active\")"
      ],
      "metadata": {
        "id": "bxuTX_hClOIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For step 2. \n",
        "# Use groupby analysis to identify \"Standard Type\" with only numerical \"pChEMBL Value\"\n",
        "# Return a list of selected \"Standard Type\"\n",
        "def Select_Standard_Type(DF):\n",
        "    # group the dataframe by type and inspect the pchembl_value column\n",
        "    Grouped = DF.groupby('Standard Type')['pChEMBL Value']\n",
        "\n",
        "    Standard_Type = []\n",
        "\n",
        "    # check if any group has only numerical values or only None values\n",
        "    for group_name, group_values in Grouped:\n",
        "        group_values = group_values.dropna()\n",
        "        if len(group_values) == 0:\n",
        "            print(f\"All values in group {group_name} are None.\")\n",
        "        elif all(isinstance(val, float) for val in group_values):\n",
        "            print(f\"All values in group {group_name} are numerical.\")\n",
        "            Standard_Type.append(group_name)\n",
        "        else:\n",
        "            print(f\"Group {group_name} has mixed data types.\")\n",
        "        \n",
        "    print(\"Standard potency measurement types to keep are:\", Standard_Type)\n",
        "    \n",
        "    return Standard_Type\n",
        "\n",
        "# For step 7. \n",
        "# Some compounds have multiple bioactivity data reported. \n",
        "# The mean and std (standard deviation) of pChEMBL Values are calculated for each unique compound, any compound with disagreeing pChEMBL Values (large std) are discarded\n",
        "# 'mean' is merged to the dataset\n",
        "def Mean_Std_pChEMBL_Value(Filtered_DF):\n",
        "    print(\"Number of unique compounds: \",Filtered_DF['Molecule ChEMBL ID'].nunique())\n",
        "    \n",
        "    # Group by \"Molecule ChEMBL ID\" and calculate average and standard deviation of \"pChEMBL Value\"\n",
        "    Grouped_Filtered_DF = Filtered_DF.groupby('Molecule ChEMBL ID')['pChEMBL Value'].agg(['mean', 'std'])\n",
        "    \n",
        "    # The number of unique compound with std of pChEMBL Value greater than 2.0\n",
        "    n_drop = Grouped_Filtered_DF[Grouped_Filtered_DF['std']>2.0].shape[0]\n",
        "    print(\"There are\",n_drop, \"compounds with std pChEMBL Value > 2.0\")\n",
        "    \n",
        "    # Get the \"Molecule ChEMBL ID\" with a std pChEMBL Value <= 2.0\n",
        "    Remaining_IDs = Grouped_Filtered_DF[Grouped_Filtered_DF['std'].isna() | (Grouped_Filtered_DF['std']<=2.0)].index.tolist()\n",
        "    print(\"Number of unique compounds to keep: \",len(Remaining_IDs))\n",
        "    \n",
        "    # Merged Filtered_DF and Grouped_Filtered_DF by \"Molecule ChEMBL ID\" and add mean pChEMBL \n",
        "    Merged_DF = pd.merge(Filtered_DF, Grouped_Filtered_DF[['mean']], left_on='Molecule ChEMBL ID', right_index=True, how='left')\n",
        "    # Keep only \"Molecule ChEMBL ID\" with std pChEMBL Value <= 2.0 according to Remaining_IDs\n",
        "    Merged_DF_subset = Merged_DF.set_index('Molecule ChEMBL ID').loc[Remaining_IDs]\n",
        "    # Drop duplicates based on the index ('Molecule ChEMBL ID')\n",
        "    Merged_DF_unique = Merged_DF_subset[~Merged_DF_subset.index.duplicated(keep='first')]\n",
        "\n",
        "    return Merged_DF_unique\n",
        "\n",
        "# Step 1 - 7\n",
        "# This function read in the original dataset, then return the filtered dataset with unique compounds. \n",
        "# Additionally, also clean out the smiles of all unique compounds. \n",
        "def get_filtered_df(DF):\n",
        "    # Print out the first 20 rows of the original dataset\n",
        "    print(\"*\"*20,\"Original bioactivity dataset\", \"*\"*20)\n",
        "    print(DF.loc[:,['Molecular Weight','Standard Type','pChEMBL Value','Comment','Assay Type']].head(20))\n",
        "    print(\"Number of bioactivity data points:\", DF.shape[0])\n",
        "    print(\"Number of unique compounds:\",DF['Molecule ChEMBL ID'].nunique())\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    # For step 6\n",
        "    # Convert 'Molecular Weight' to float datatype, since we need to filter all compounds that are too large\n",
        "    DF['Molecular Weight']=pd.to_numeric(DF['Molecular Weight'], errors='coerce')\n",
        "    DF['Molecular Weight'].replace('None', np.nan, inplace=True)\n",
        "    DF['Molecular Weight'] = DF['Molecular Weight'].astype(float)  \n",
        "    \n",
        "    # For step 3\n",
        "    # Convert any comment strings contain one or more digits and nothing else to NaN, then only keep NaN comments\n",
        "    DF['Comment'] = DF['Comment'].replace(to_replace=r'^\\d+$', value=np.nan, regex=True)\n",
        "    DF['Comment'] = DF['Comment'].replace(to_replace=['Active','active'], value=np.nan, regex=True)\n",
        "\n",
        "    # For step 2\n",
        "    # Identify the 'Standard Type' that has only numerical 'pChEMBL Value' and keep only those\n",
        "    print(\"Calling function Select_Standard_Type\")\n",
        "    Standard_Type = Select_Standard_Type(DF)\n",
        "    \n",
        "    # Apply the data filters \n",
        "    Filtered_DF = DF[DF['Comment'].isna()] # Step 3: Drop any non NaN comments \n",
        "    Filtered_DF = Filtered_DF[Filtered_DF['Assay Type']=='B'] # Step 4: Keep only 'B' Assay Type\n",
        "    Filtered_DF = Filtered_DF[Filtered_DF['Standard Relation']==\"'='\"] # Step 5 \n",
        "    Filtered_DF = Filtered_DF.dropna(subset=['pChEMBL Value']) # Step 7: Drop any NaN pChEMBL Values\n",
        "    Filtered_DF = Filtered_DF[Filtered_DF['Standard Type'].isin(Standard_Type)] # Step 2\n",
        "    \n",
        "    Filtered_DF = Filtered_DF[Filtered_DF['Molecular Weight']<=1000] # Step 6\n",
        "    \n",
        "    # Print out the first 20 rows of the filtered dataset with above dataframe sub settings \n",
        "    print(\"\\n\")\n",
        "    print(\"*\"*20,\"Filtered bioactivity dataset\", \"*\"*20)\n",
        "    print(Filtered_DF.loc[:,['Molecular Weight','Standard Type','pChEMBL Value','Comment','Assay Type']].head(20))\n",
        "    print(\"Number of bioactivity data points:\",Filtered_DF.shape[0])\n",
        "    print(\"Number of unique compounds:\",Filtered_DF['Molecule ChEMBL ID'].nunique())\n",
        "    \n",
        "    print(\"\\n\")\n",
        "    print(\"*\"*20,\"Filtered unique bioactivity dataset\", \"*\"*20)\n",
        "    print(\"Calling function Mean_Std_pChEMBL_Value\")\n",
        "    Merged_DF_unique = Mean_Std_pChEMBL_Value(Filtered_DF)\n",
        "    \n",
        "    print(\"\\n\")\n",
        "    print(\"*\"*20,\"Filtered unique bioactivity dataset with pChEMBL Value >= 6.0\", \"*\"*20)\n",
        "    Merged_DF_unique = Merged_DF_unique[Merged_DF_unique['mean']>=6] # Step 7\n",
        "    print(\"Final Number of Active:\",Merged_DF_unique.shape[0])\n",
        "    \n",
        "    # Drop any row without 'Smiles'\n",
        "    print(\"\\n\")\n",
        "    print(\"*\"*20,\"Process and clean SMILES\", \"*\"*20)\n",
        "    Merged_DF_unique = Merged_DF_unique.dropna(subset=['Smiles'])\n",
        "    \n",
        "    # For molecule that has \".\" in the \"Smiles\" string, split the \"Smiles\" and keep the compound part\n",
        "    Merged_DF_unique['Smiles']= Merged_DF_unique['Smiles'].apply(lambda x: max(x.split(\".\"),key=len))\n",
        "    print(\"There are\", sum(Merged_DF_unique['Smiles'].str.find('.') != -1), \"records with '.' in their canonical smiles string\")\n",
        "    \n",
        "    return Merged_DF_unique"
      ],
      "metadata": {
        "id": "OnHvgYtMlK8g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(file_path+\"CHEMBL3371.csv\", delimiter=';', skiprows=0, low_memory=False)"
      ],
      "metadata": {
        "id": "qfmq2GXrpuyM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "7b0c3c89-4103-4822-d97d-0e7b65bcacac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c59d9709ad93>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"CHEMBL3371.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df_unique = get_filtered_df(df)"
      ],
      "metadata": {
        "id": "hqvcrO0jpyeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQTMKDKUqDeT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}